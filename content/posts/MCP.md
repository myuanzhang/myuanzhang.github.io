---
title: "MCP"
date: 2025-01-01
draft: false
---

这是我的第一篇 Hugo 博客文章。

这句话中的 “a full round-trip from model → MCP client → MCP server → back to the model” 描述的是在使用 MCP（Model Control Protocol）架构进行工具调用时，一次完整交互所经历的数据流向和系统组件顺序。我们可以逐段拆解这个流程

## 端到端流程

在典型的基于 MCP（Model Control Protocol）或类似工具调用架构（如 LangChain、OpenAI Function Calling 等）的智能体系统中，从用户发起请求到最终获得响应的完整端到端流程为：

```
User → MCP Client → Model → (Tool Call) → MCP Client → MCP Server → (Result) → MCP Client → Model → User
```

1. **User** 发送初始 prompt（例如：“查一下明天北京的天气”）。

2. **MCP Client**（即 Agent 的运行时环境）接收用户输入，并将其格式化为模型可理解的对话上下文（可能包括系统提示、工具元数据等）。

3. **Model** 接收上下文，进行推理。若判断需要调用工具，则生成一个结构化的工具调用请求（如 `{"tool": "get_weather", "args": {"city": "Beijing", "date": "2025-12-24"}}`）。

4. MCP Client

    捕获模型输出，识别出这是一个工具调用（而非最终回答），于是：

   - 验证参数；
   - 查找对应工具的 schema；
   - 向 **MCP Server** 发起 RPC 或 HTTP 请求。

5. **MCP Server** 执行实际逻辑（如调用天气 API），返回结构化结果。

6. **MCP Client** 将工具结果包装成一条“工具响应”消息，重新送入 **Model** 的上下文（作为新轮次的输入）。

7. **Model** 基于工具结果生成自然语言回答（如“明天北京晴，气温 5°C”）。

8. **MCP Client** 将最终回答返回给 **User**。

------

### 🔍 **2. 原文所指的 “full round-trip” 范围**

原文这句话：

> “every tool call introduces [...] a full round-trip from model → MCP client → MCP server → back to the model.”

它**特指单次工具调用的内部开销**，而非整个用户会话流程。作者有意将焦点放在 **“一旦模型决定调用工具，接下来会发生什么”**，因此起点是 **model**（因为那是工具调用决策点）。

这是一种**以模型为中心的视角**，强调：

- 模型不能直接执行工具；
- 必须“出去绕一圈”才能拿回结果；
- 这个“绕圈”过程代价高（延迟 + token 消耗）。

所以原文的描述虽然技术上不完整（缺少用户输入和最终输出），但在其上下文中是合理的——它讨论的是**工具调用本身的成本**，而不是整个交互生命周期。

------

### 🧩 类比理解

想象你在餐厅点菜：

- **用户** 是顾客；
- **MCP Client** 是服务员；
- **Model** 是厨师（但这个厨师不会采购食材，只会“下令”）；
- **MCP Server** 是仓库/供应商。

完整流程：

> 顾客告诉服务员要“宫保鸡丁” → 服务员告诉厨师 → 厨师说“需要花生，去仓库拿” → 服务员跑去仓库取花生 → 仓库给花生 → 服务员带回厨房 → 厨师做完菜 → 服务员端给顾客。

而原文说的 “round-trip” 只是从 **“厨师说要花生” 到 “花生回到厨师手里”** 这一段。它没提顾客和服务员最初的沟通，因为重点是“每次要食材都得跑一趟仓库，很慢”。





## 工具调用触发后的内部往返单次工具调用子流程

在使用 MCP（Model Context Protocol）架构进行工具调用时，一次完整交互所经历的数据流向和系统组件顺序是：model → MCP Client → MCP Server → model

### 1. **model（大语言模型）**

- 起点是 LLM（大语言模型）本身。当模型在推理过程中判断需要调用某个外部工具（例如查询数据库、执行计算等）时，它会生成一个**工具调用请求**（通常包含工具名称和参数）。

### 2. **→ MCP client（MCP 客户端）**

- 这个工具调用请求首先被发送到 

  MCP 客户端

  。MCP 客户端通常运行在 LLM 所在的系统或代理（agent）中，负责：

  - 解析模型输出的工具调用格式；
  - 验证参数是否符合该工具的 schema；
  - 将调用封装成标准的 MCP 协议消息。

### 3. **→ MCP server（MCP 服务器）**

- MCP 客户端将封装好的请求发送给 

  MCP 服务器

  。MCP 服务器托管了实际的工具实现（即“工具函数”），它的职责包括：

  - 接收并解析 MCP 请求；
  - 根据工具名调用对应的本地或远程服务；
  - 执行工具逻辑，获取结果；
  - 将结果按照预定义的格式返回给客户端。

### 4. **→ back to the model（返回模型）**

- MCP 客户端收到服务器返回的结果后，将其**注入回 LLM 的上下文**（通常作为一条“工具响应”消息）。
- 模型基于这个新信息继续推理，生成下一步的回答或决定是否需要再次调用其他工具。

------

### 为什么这被称为 “full round-trip”？

因为整个过程形成了一个闭环：
**模型发起 → 客户端处理 → 服务端执行 → 结果返回 → 模型继续**。
任何一次工具调用都必须走完这一整套流程，无法跳过中间环节。

------

### 为什么这会导致延迟（latency）问题？

- 每一步都可能引入延迟：网络传输（client ↔ server）、序列化/反序列化、工具执行时间、上下文重建等。
- 如果工具调用链很长（比如需要连续调用多个工具），延迟会线性甚至指数增长。
- 对于实时性要求高的应用（如对话机器人、实时决策系统），这种“重协议 + 多跳”架构就显得过于笨重。

------

### 总结

“a full round-trip from model → MCP client → MCP server → back to the model” 强调了 MCP 工具调用机制的**端到端通信路径**，也揭示了其在**效率与延迟**方面的根本瓶颈：每次调用都不是本地轻量操作，而是一次完整的跨组件协作，代价高昂。
